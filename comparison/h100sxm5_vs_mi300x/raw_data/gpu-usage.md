## 1x meta-llama/Llama-3.1-405B-FP8 in 8x H100 SXM5
Loading model weights took `56.7677 GB` in each GPU
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.90.12              Driver Version: 550.90.12      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:61:00.0 Off |                    0 |
| N/A   48C    P0            464W /  700W |   72770MiB /  81559MiB |     97%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  |   00000000:62:00.0 Off |                    0 |
| N/A   51C    P0            460W /  700W |   70690MiB /  81559MiB |     96%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  |   00000000:63:00.0 Off |                    0 |
| N/A   52C    P0            469W /  700W |   70690MiB /  81559MiB |     97%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  |   00000000:64:00.0 Off |                    0 |
| N/A   48C    P0            460W /  700W |   70690MiB /  81559MiB |     97%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  |   00000000:6A:00.0 Off |                    0 |
| N/A   47C    P0            460W /  700W |   70690MiB /  81559MiB |     97%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  |   00000000:6B:00.0 Off |                    0 |
| N/A   52C    P0            457W /  700W |   70690MiB /  81559MiB |     96%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  |   00000000:6C:00.0 Off |                    0 |
| N/A   49C    P0            448W /  700W |   70690MiB /  81559MiB |     96%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  |   00000000:6D:00.0 Off |                    0 |
| N/A   46C    P0            453W /  700W |   70210MiB /  81559MiB |     96%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

## 1x meta-llama/Llama-3.1-405B-FP8 in 8x Mi300x
Loading model weights took `56.7677 GB` in each GPU
============================================ ROCm System Management Interface ============================================
====================================================== Concise Info ======================================================
Device  Node  IDs              Temp        Power     Partitions          SCLK    MCLK    Fan  Perf  PwrCap  VRAM%  GPU%  
              (DID,     GUID)  (Junction)  (Socket)  (Mem, Compute, ID)                                                  
==========================================================================================================================
0       2     0x74a1,   60024  46.0°C      130.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  71%    0%    
1       3     0x74a1,   45760  43.0°C      124.0W    NPS1, SPX, 0        131Mhz  900Mhz  0%   auto  750.0W  69%    0%    
2       4     0x74a1,   19599  42.0°C      128.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  69%    0%    
3       5     0x74a1,   52575  48.0°C      136.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  69%    0%    
4       6     0x74a1,   11160  46.0°C      127.0W    NPS1, SPX, 0        131Mhz  900Mhz  0%   auto  750.0W  69%    0%    
5       7     0x74a1,   4769   40.0°C      123.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  69%    0%    
6       8     0x74a1,   31791  49.0°C      130.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  69%    0%    
7       9     0x74a1,   2490   42.0°C      124.0W    NPS1, SPX, 0        131Mhz  900Mhz  0%   auto  750.0W  69%    0%    
==========================================================================================================================
================================================== End of ROCm SMI Log ===================================================

## 1x amd/Meta-Llama-3.1-405B-Instruct-FP8-KV in 8x Mi300x
Loading model weights took `49.3235 GB` in each GPU
============================================ ROCm System Management Interface ============================================
====================================================== Concise Info ======================================================
Device  Node  IDs              Temp        Power     Partitions          SCLK    MCLK    Fan  Perf  PwrCap  VRAM%  GPU%  
              (DID,     GUID)  (Junction)  (Socket)  (Mem, Compute, ID)                                                  
==========================================================================================================================
0       2     0x74a1,   60024  47.0°C      131.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  83%    0%    
1       3     0x74a1,   45760  43.0°C      125.0W    NPS1, SPX, 0        131Mhz  900Mhz  0%   auto  750.0W  81%    0%    
2       4     0x74a1,   19599  42.0°C      128.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  81%    0%    
3       5     0x74a1,   52575  49.0°C      138.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  81%    0%    
4       6     0x74a1,   11160  47.0°C      128.0W    NPS1, SPX, 0        131Mhz  900Mhz  0%   auto  750.0W  81%    0%    
5       7     0x74a1,   4769   40.0°C      124.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  81%    0%    
6       8     0x74a1,   31791  50.0°C      131.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  81%    0%    
7       9     0x74a1,   2490   42.0°C      123.0W    NPS1, SPX, 0        131Mhz  900Mhz  0%   auto  750.0W  81%    0%    
==========================================================================================================================
================================================== End of ROCm SMI Log ===================================================

## 1x amd/Meta-Llama-3.1-405B-Instruct-FP8-KV in 4x Mi300x
Loading model weights took `97.4347 GB` in each GPU
============================================ ROCm System Management Interface ============================================
====================================================== Concise Info ======================================================
Device  Node  IDs              Temp        Power     Partitions          SCLK    MCLK    Fan  Perf  PwrCap  VRAM%  GPU%  
              (DID,     GUID)  (Junction)  (Socket)  (Mem, Compute, ID)                                                  
==========================================================================================================================
0       2     0x74a1,   60024  47.0°C      131.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  96%    0%    
1       3     0x74a1,   45760  43.0°C      125.0W    NPS1, SPX, 0        131Mhz  900Mhz  0%   auto  750.0W  95%    0%    
2       4     0x74a1,   19599  41.0°C      128.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  95%    0%    
3       5     0x74a1,   52575  48.0°C      137.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  95%    0%    
4       6     0x74a1,   11160  39.0°C      122.0W    NPS1, SPX, 0        131Mhz  900Mhz  0%   auto  750.0W  0%     0%    
5       7     0x74a1,   4769   36.0°C      120.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  0%     0%    
6       8     0x74a1,   31791  41.0°C      123.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  0%     0%    
7       9     0x74a1,   2490   38.0°C      120.0W    NPS1, SPX, 0        131Mhz  900Mhz  0%   auto  750.0W  0%     0%    
==========================================================================================================================
================================================== End of ROCm SMI Log ===================================================

## 2x amd/Meta-Llama-3.1-405B-Instruct-FP8-KV in 8x Mi300x
Loading model weights took `97.4347 GB` in each GPU
============================================ ROCm System Management Interface ============================================
====================================================== Concise Info ======================================================
Device  Node  IDs              Temp        Power     Partitions          SCLK    MCLK    Fan  Perf  PwrCap  VRAM%  GPU%  
              (DID,     GUID)  (Junction)  (Socket)  (Mem, Compute, ID)                                                  
==========================================================================================================================
0       2     0x74a1,   60024  56.0°C      142.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  79%    0%    
1       3     0x74a1,   45760  48.0°C      129.0W    NPS1, SPX, 0        131Mhz  900Mhz  0%   auto  750.0W  79%    0%    
2       4     0x74a1,   19599  46.0°C      132.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  79%    0%    
3       5     0x74a1,   52575  58.0°C      151.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  79%    0%    
4       6     0x74a1,   11160  43.0°C      124.0W    NPS1, SPX, 0        131Mhz  900Mhz  0%   auto  750.0W  79%    0%    
5       7     0x74a1,   4769   38.0°C      122.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  79%    0%    
6       8     0x74a1,   31791  45.0°C      127.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  79%    0%    
7       9     0x74a1,   2490   40.0°C      122.0W    NPS1, SPX, 0        132Mhz  900Mhz  0%   auto  750.0W  79%    0%    
==========================================================================================================================
================================================== End of ROCm SMI Log ===================================================





