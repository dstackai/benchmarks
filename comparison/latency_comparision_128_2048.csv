gpu,input_len,output_len,batch_size,end_to_end_latency,tokens_per_second
8xH100-meta-Llama-31-405B-FP8,128,2048,4,71.27394036,122.1203704
8xH100-meta-Llama-31-405B-FP8,128,2048,8,75.05596489,231.9335981
8xH100-meta-Llama-31-405B-FP8,128,2048,16,75.82455635,459.1652319
8xH100-meta-Llama-31-405B-FP8,128,2048,32,78.37005056,888.5026806
8xH100-meta-Llama-31-405B-FP8,128,2048,64,123.1509682,1130.839668
8xH100-meta-Llama-31-405B-FP8,128,2048,128,214.67,1297.443
8xH100-meta-Llama-31-405B-FP8,128,2048,256,399.64,1393.8654
8xMi300x-meta-Llama-31-405B-FP8,128,2048,4,279.115799,31.1841897
8xMi300x-meta-Llama-31-405B-FP8,128,2048,8,287.809995,60.4843484
8xMi300x-meta-Llama-31-405B-FP8,128,2048,16,290.992608,119.645651
8xMi300x-meta-Llama-31-405B-FP8,128,2048,32,293.69183,237.092056
8xMi300x-meta-Llama-31-405B-FP8,128,2048,64,307.312373,453.167565
8xMi300x-meta-Llama-31-405B-FP8,128,2048,128,340.863436,817.124897
8xMi300x-meta-Llama-31-405B-FP8,128,2048,256,438.203916,1271.22552
8xMi300x-amd-Llama-31-405B-Instruct-FP8-KV,128,2048,4,58.4253277,148.976486
8xMi300x-amd-Llama-31-405B-Instruct-FP8-KV,128,2048,8,60.1839962,289.24633
8xMi300x-amd-Llama-31-405B-Instruct-FP8-KV,128,2048,16,64.6714823,538.351662
8xMi300x-amd-Llama-31-405B-Instruct-FP8-KV,128,2048,32,72.2652871,963.560829
8xMi300x-amd-Llama-31-405B-Instruct-FP8-KV,128,2048,64,89.2323783,1560.6891
8xMi300x-amd-Llama-31-405B-Instruct-FP8-KV,128,2048,128,121.842156,2285.97399
8xMi300x-amd-Llama-31-405B-Instruct-FP8-KV,128,2048,256,194.336858,2866.44544